# Data-Lake-On-Premises-with-Apache-Hadoop-HDFS-and-ETL-process-for-a-Data-Warehouse
In this project we build a Data Lake On-Premises using containers Docker and batch data ingestion using Apache Nifi. After the data ingestion, we did the ETL process to load in an Data Warehouse

## Services provided:
- [x] Creation of Data Lake On-Premises
- [x] Use of Docker to implement the Hadoop Cluster
- [x] Creation of Namenode's Image and Container
- [x] Creation of 2 Datanode's Image and Container
- [x] Image criation with Docker File
- [x] Batch data acquisition
- [x] ETL process to load data in a Data Warehouse


## Developed Skills:
- [x] Docker
- [x] Apache Hadoop HDFS
- [x] Apache NiFi
- [x] Docker File
- [x] PgAdmin
- [x] Postgres

## Architecture Diagram:

<img src="/Architecture Diagram.png">

I made this diagram using [Diagrams.net](https://app.diagrams.net/)
