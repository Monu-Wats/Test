# Preparação dos DataNodes

1- Faça o download do Apache Hadoop e do JDK 8, coloque na pasta "binarios", descompacte os arquivos e renomeie as pastas.

2- Abra o terminal ou prompt de comando, navegue até a pasta do DataNode e execute a instrução abaixo para criar a imagem:

docker build . -t datanode:datalake

3- Precisaremos de uma rede. Verifique se a rede dl_net criada no capítulo anterior está criada:

docker network ls

4- Crie e inicialize o container de cada datanode com cada instrução abaixo:

docker run -it -d --net dl_net --hostname datanode1 --name datanode1 datanode:datalake

docker run -it -d --net dl_net --hostname datanode2 --name datanode2 datanode:datalake

5- Acesse CADA container usando a CLI no Docker Desktop e execute as instruções abaixo:

# Restart do serviço ssh
sudo service ssh restart

# Ajuste dos privilégios
sudo chown -R hduser:hduser /home/hduser/jdk
sudo chown -R hduser:hduser /home/hduser/hadoop

# Crie a pasta ~/.ssh
mkdir ~/.ssh

# Crie o arquivo ~/.ssh/authorized_keys
touch ~/.ssh/authorized_keys

# Ajuste o privilégio
chmod 600 ~/.ssh/authorized_keys

# Copie a chave que está em /home/hduser/.ssh/authorized_keys no NameNode para o mesmo arquivo em cada datanode.

# Start do serviço do DataNode
hdfs --daemon start datanode

# Se precisar parar o serviço:
hdfs --daemon stop datanode

Obs: Se não funcionar o endereço 0.0.0.0 use localhost